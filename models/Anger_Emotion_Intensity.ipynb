{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anger Emotion Intensity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rasmika Billa"
      ],
      "metadata": {
        "id": "-UNaSYUHwoOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing and Importing the required Libraries"
      ],
      "metadata": {
        "id": "QzFShcwowhpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wordsegment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5hl8nXUkAvO",
        "outputId": "282c369d-069d-4b62-99a7-5db5d9aca08c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordsegment in /usr/local/lib/python3.7/dist-packages (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbEWbKiOj0tc",
        "outputId": "f9672b0d-101a-4a13-9816-bfc3021a8c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.util import ngrams  \n",
        "import collections\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from wordsegment import segment, load\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "nltk.download(\"stopwords\")\n",
        "load()\n",
        "replace_by_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "replace_symbol = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Datasets"
      ],
      "metadata": {
        "id": "Ke5hr5TtwsPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd. read_csv(\"anger-ratings-0to1.train.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
        "val = pd. read_csv(\"anger-ratings-0to1.dev.target.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
        "val_gold = pd. read_csv(\"anger-ratings-0to1.dev.gold.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
        "test = pd. read_csv(\"anger-ratings-0to1.test.target.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
        "test_gold = pd. read_csv(\"anger-ratings-0to1.test.target (1).txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])"
      ],
      "metadata": {
        "id": "sfAi0n3gkHOT"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frXmD3cKkMzN",
        "outputId": "51d61c07-0698-46eb-f6cc-12607cfa12b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the given data"
      ],
      "metadata": {
        "id": "TzSo_y7Owva-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tknzr = TweetTokenizer(reduce_len=True, preserve_case=False, strip_handles=False)\n",
        "from emot.emo_unicode import UNICODE_EMOJI\n",
        "def convert_emojis(text):\n",
        "    for emot in UNICODE_EMOJI:\n",
        "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
        "    return text\n",
        "\n",
        "def text_preprocess(text):\n",
        "    FLAGS = re.MULTILINE | re.DOTALL\n",
        "    eyes = r\"[8:=;]\"\n",
        "    nose = r\"['`\\-]?\"\n",
        "\n",
        "    def re_sub(pattern, repl):\n",
        "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
        "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
        "    text = re_sub(r\"/\",\" / \")\n",
        "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
        "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
        "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
        "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
        "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
        "    text = re_sub(r\"<3\",\"<heart>\")\n",
        "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
        "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
        "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
        "    text = re_sub(r\"#\\S+\", lambda hashtag: \" \".join(segment(hashtag.group()[1:]))) \n",
        "\n",
        "    tokens = tknzr.tokenize(text.lower())\n",
        "    return \" \".join(tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "9gP6Ni0JkZNd"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding the metrics given for the task"
      ],
      "metadata": {
        "id": "aX3W2uuAw0WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metric(y_pred, y, title):\n",
        "    p1 = pearsonr(y_pred, y)[0]\n",
        "    s1 = spearmanr(y_pred, y)[0]\n",
        "    ind = np.where(y >= 0.5)\n",
        "    ydt = np.take(y_pred, ind).reshape(-1)\n",
        "    ydpt = np.take(y.to_numpy(), ind).reshape(-1)\n",
        "    p2 = pearsonr(ydt, ydpt)[0]\n",
        "    s2 = spearmanr(ydt, ydpt)[0]\n",
        "    print(title)\n",
        "    res = {}\n",
        "    res['Pearsonr'] = p1\n",
        "    res['Spearmanr'] = s1\n",
        "    res['Pearsonr >= 0.5'] = p2\n",
        "    res['Spearmanr >= 0.5'] = s2\n",
        "    result = pd.DataFrame(res.items(), columns=['metrics', 'Value'], index=None)\n",
        "    return result"
      ],
      "metadata": {
        "id": "0QliqQOUkq3t"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML algos used - Random Forest and Support Vector Machine"
      ],
      "metadata": {
        "id": "-OQJbyk6xBSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ml_model(X_train, X_test, y_train, y_test, val_X, val_y):\n",
        "    prediction_accuracy = {}\n",
        "    \n",
        "    # RF\n",
        "    _RF = RandomForestRegressor(n_estimators = 1000, oob_score=True)\n",
        "    _RF.fit(X_train, y_train)\n",
        "    _RF_prediction = _RF.predict(X_test)\n",
        "    val_RF_prediction = _RF.predict(val_X)\n",
        "\n",
        "    print(metric(_RF_prediction, y_test, \"Train-set \"))\n",
        "    print(metric(val_RF_prediction, val_y, \"Test-set \"))\n",
        "    print('\\n ')\n",
        "    \n",
        "    # SVM\n",
        "    _SVC = SVR( kernel = 'rbf')\n",
        "    _SVC.fit(X_train, y_train)\n",
        "    _SVC_prediction = _SVC.predict(X_test)\n",
        "    val_SVC_prediction = _SVC.predict(val_X)\n",
        "    \n",
        "    print(metric(_SVC_prediction, y_test, \"Train-set \"))\n",
        "    print(metric(val_SVC_prediction, val_y, \"Test-set \"))\n",
        "    print('\\n ')\n",
        "    \n",
        "    #accuracy DataFram\n",
        "    prediction_accuracy_df = pd.DataFrame(prediction_accuracy.items(), columns=['Model', 'Accuracy'], index=None)\n",
        "    return prediction_accuracy_df"
      ],
      "metadata": {
        "id": "iyczHRMmk3Qu"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL Vectorization "
      ],
      "metadata": {
        "id": "VoQQzBE6xJaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Vectorization(X, y, val_X, val_y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "    tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=1000, min_df=20, stop_words= STOPWORDS )\n",
        "    X_train = tfidf.fit_transform(X_train).toarray()\n",
        "    X_test = tfidf.transform(X_test).toarray()\n",
        "    val_X = tfidf.transform(val_X).toarray()\n",
        "    return X_train, X_test, y_train, y_test, val_X, val_y"
      ],
      "metadata": {
        "id": "Fp-PgvCfmf94"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ml(train, val, test, prePro=False):\n",
        "  train_val = pd.concat([train, val], ignore_index=True)\n",
        "  if prePro:\n",
        "    train['tweet'] = train['tweet'].apply(convert_emojis)\n",
        "    val['tweet'] = val['tweet'].apply(convert_emojis)\n",
        "    test['tweet'] = test['tweet'].apply(convert_emojis)\n",
        "    train_val['tweet'] = train_val['tweet'].apply(convert_emojis)\n",
        "\n",
        "    train['tweet'] = train['tweet'].apply(text_preprocess)\n",
        "    val['tweet'] = val['tweet'].apply(text_preprocess)\n",
        "    test['tweet'] = test['tweet'].apply(text_preprocess)\n",
        "    train_val['tweet'] = train_val['tweet'].apply(text_preprocess)\n",
        "  \n",
        "\n",
        "  # Train\n",
        "  X_train, X_test, y_train, y_test,val_X, val_y = Vectorization(train.tweet ,train.score , val_gold.tweet , val_gold.score )\n",
        "  p_df = ml_model(X_train, X_test, y_train, y_test, val_X, val_y)\n",
        "  # Test\n",
        "  #X_train, X_test, y_train, y_test,val_X, val_y = Vectorization(train_val.tweet ,train_val.score , test_gold.tweet , test_gold.score)\n",
        "  #p_df = ml_model(X_train, X_test, y_train, y_test, val_X, val_y)"
      ],
      "metadata": {
        "id": "DmoJhvyHmjva"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values before pre-processing"
      ],
      "metadata": {
        "id": "klfZMnPlxQfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ml(train, val, test, prePro=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqXy-9d5mozZ",
        "outputId": "8ea82605-4acb-461b-b0a1-1b9cf83bfd29"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.335389\n",
            "1         Spearmanr  0.276699\n",
            "2   Pearsonr >= 0.5  0.135294\n",
            "3  Spearmanr >= 0.5  0.098088\n",
            "Test-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.305412\n",
            "1         Spearmanr  0.235412\n",
            "2   Pearsonr >= 0.5  0.301790\n",
            "3  Spearmanr >= 0.5  0.321941\n",
            "\n",
            " \n",
            "Train-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.323376\n",
            "1         Spearmanr  0.273366\n",
            "2   Pearsonr >= 0.5  0.128668\n",
            "3  Spearmanr >= 0.5  0.064585\n",
            "Test-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.294480\n",
            "1         Spearmanr  0.202963\n",
            "2   Pearsonr >= 0.5  0.304415\n",
            "3  Spearmanr >= 0.5  0.272220\n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values after pre-processing"
      ],
      "metadata": {
        "id": "cWczWiU3xZyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ml(train, val, test, prePro=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8rpgQl4vjBH",
        "outputId": "442a8f6e-7a73-4bbe-ca72-36e33cb35e3c"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.262652\n",
            "1         Spearmanr  0.237654\n",
            "2   Pearsonr >= 0.5  0.013751\n",
            "3  Spearmanr >= 0.5  0.009119\n",
            "Test-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.269226\n",
            "1         Spearmanr  0.168233\n",
            "2   Pearsonr >= 0.5  0.306820\n",
            "3  Spearmanr >= 0.5  0.257248\n",
            "\n",
            " \n",
            "Train-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.236251\n",
            "1         Spearmanr  0.181450\n",
            "2   Pearsonr >= 0.5 -0.000156\n",
            "3  Spearmanr >= 0.5  0.004860\n",
            "Test-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.295609\n",
            "1         Spearmanr  0.169357\n",
            "2   Pearsonr >= 0.5  0.348311\n",
            "3  Spearmanr >= 0.5  0.269418\n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL Neural network model"
      ],
      "metadata": {
        "id": "SU-iCiGS0ruc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NN_model(X_train, X_test, y_train, y_test, val_X, val_y):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
        "  model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "  model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split = 0.2)\n",
        "  pre = model.predict(X_test)\n",
        "  p = []\n",
        "  for i in pre:\n",
        "    p.append(i[0])\n",
        "  print(metric(p, y_test, \"Train-set \"))\n",
        "  pre_val = model.predict(val_X)\n",
        "  p_val = []\n",
        "  for i in pre_val:\n",
        "    p_val.append(i[0])\n",
        "  print(metric(p_val, val_y, \"Test-set \"))\n",
        "  \n",
        "  return None"
      ],
      "metadata": {
        "id": "Yd5S_WLdznhS"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_NN(train, val, test, prePro=False):\n",
        "  train_val = pd.concat([train, val], ignore_index=True)\n",
        "  if prePro:\n",
        "    train['tweet'] = train['tweet'].apply(convert_emojis)\n",
        "    val['tweet'] = val['tweet'].apply(convert_emojis)\n",
        "    test['tweet'] = test['tweet'].apply(convert_emojis)\n",
        "    train_val['tweet'] = train_val['tweet'].apply(convert_emojis)\n",
        "\n",
        "    train['tweet'] = train['tweet'].apply(text_preprocess)\n",
        "    val['tweet'] = val['tweet'].apply(text_preprocess)\n",
        "    test['tweet'] = test['tweet'].apply(text_preprocess)\n",
        "    train_val['tweet'] = train_val['tweet'].apply(text_preprocess)\n",
        "\n",
        "  # Train\n",
        "  X_train, X_test, y_train, y_test,val_X, val_y = Vectorization(train.tweet ,train.score , val_gold.tweet , val_gold.score )\n",
        "  p_df = NN_model(X_train, X_test, y_train, y_test, val_X, val_y)\n",
        "  # Test\n",
        "  #print(\"*\"*24, \"Train + Validation => Test\", \"*\"*24, \"\\n\")\n",
        "  #X_train, X_test, y_train, y_test,val_X, val_y = Vectorization(train_val.tweet ,train_val.score , test_gold.tweet , test_gold.score)\n",
        "  #p_df = NN_model(X_train, X_test, y_train, y_test, val_X, val_y)"
      ],
      "metadata": {
        "id": "m9AODvmjzuat"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before pre-processing"
      ],
      "metadata": {
        "id": "gy7mn3iO0f6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_NN(train, val, test, prePro=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV49UCV3z5U1",
        "outputId": "c07cc735-df19-459f-c25f-37a9d9d932b9"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.2716 - mean_absolute_error: 0.2716 - val_loss: 0.1344 - val_mean_absolute_error: 0.1344\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1329 - mean_absolute_error: 0.1329 - val_loss: 0.1331 - val_mean_absolute_error: 0.1331\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1305 - mean_absolute_error: 0.1305 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1304 - mean_absolute_error: 0.1304 - val_loss: 0.1212 - val_mean_absolute_error: 0.1212\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1297 - mean_absolute_error: 0.1297 - val_loss: 0.1257 - val_mean_absolute_error: 0.1257\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1233 - mean_absolute_error: 0.1233 - val_loss: 0.1312 - val_mean_absolute_error: 0.1312\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1258 - val_mean_absolute_error: 0.1258\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1226 - mean_absolute_error: 0.1226 - val_loss: 0.1335 - val_mean_absolute_error: 0.1335\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1240 - mean_absolute_error: 0.1240 - val_loss: 0.1237 - val_mean_absolute_error: 0.1237\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1196 - mean_absolute_error: 0.1196 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1209 - mean_absolute_error: 0.1209 - val_loss: 0.1232 - val_mean_absolute_error: 0.1232\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1192 - mean_absolute_error: 0.1192 - val_loss: 0.1351 - val_mean_absolute_error: 0.1351\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1275 - mean_absolute_error: 0.1275 - val_loss: 0.1303 - val_mean_absolute_error: 0.1303\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1189 - mean_absolute_error: 0.1189 - val_loss: 0.1226 - val_mean_absolute_error: 0.1226\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1198 - mean_absolute_error: 0.1198 - val_loss: 0.1241 - val_mean_absolute_error: 0.1241\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1172 - mean_absolute_error: 0.1172 - val_loss: 0.1236 - val_mean_absolute_error: 0.1236\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1205 - mean_absolute_error: 0.1205 - val_loss: 0.1314 - val_mean_absolute_error: 0.1314\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1254 - mean_absolute_error: 0.1254 - val_loss: 0.1496 - val_mean_absolute_error: 0.1496\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1279 - mean_absolute_error: 0.1279 - val_loss: 0.1276 - val_mean_absolute_error: 0.1276\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1168 - mean_absolute_error: 0.1168 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1149 - mean_absolute_error: 0.1149 - val_loss: 0.1281 - val_mean_absolute_error: 0.1281\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1143 - mean_absolute_error: 0.1143 - val_loss: 0.1292 - val_mean_absolute_error: 0.1292\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1145 - mean_absolute_error: 0.1145 - val_loss: 0.1265 - val_mean_absolute_error: 0.1265\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1174 - mean_absolute_error: 0.1174 - val_loss: 0.1268 - val_mean_absolute_error: 0.1268\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1181 - mean_absolute_error: 0.1181 - val_loss: 0.1267 - val_mean_absolute_error: 0.1267\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1110 - mean_absolute_error: 0.1110 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1187 - mean_absolute_error: 0.1187 - val_loss: 0.1261 - val_mean_absolute_error: 0.1261\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1153 - mean_absolute_error: 0.1153 - val_loss: 0.1277 - val_mean_absolute_error: 0.1277\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1124 - mean_absolute_error: 0.1124 - val_loss: 0.1326 - val_mean_absolute_error: 0.1326\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1106 - mean_absolute_error: 0.1106 - val_loss: 0.1270 - val_mean_absolute_error: 0.1270\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1101 - mean_absolute_error: 0.1101 - val_loss: 0.1312 - val_mean_absolute_error: 0.1312\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1173 - mean_absolute_error: 0.1173 - val_loss: 0.1277 - val_mean_absolute_error: 0.1277\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1149 - mean_absolute_error: 0.1149 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1101 - mean_absolute_error: 0.1101 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1111 - mean_absolute_error: 0.1111 - val_loss: 0.1272 - val_mean_absolute_error: 0.1272\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1089 - mean_absolute_error: 0.1089 - val_loss: 0.1272 - val_mean_absolute_error: 0.1272\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1152 - mean_absolute_error: 0.1152 - val_loss: 0.1253 - val_mean_absolute_error: 0.1253\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1094 - mean_absolute_error: 0.1094 - val_loss: 0.1338 - val_mean_absolute_error: 0.1338\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1137 - mean_absolute_error: 0.1137 - val_loss: 0.1262 - val_mean_absolute_error: 0.1262\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1117 - mean_absolute_error: 0.1117 - val_loss: 0.1286 - val_mean_absolute_error: 0.1286\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1097 - mean_absolute_error: 0.1097 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1097 - mean_absolute_error: 0.1097 - val_loss: 0.1293 - val_mean_absolute_error: 0.1293\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1065 - mean_absolute_error: 0.1065 - val_loss: 0.1317 - val_mean_absolute_error: 0.1317\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1065 - mean_absolute_error: 0.1065 - val_loss: 0.1281 - val_mean_absolute_error: 0.1281\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1102 - mean_absolute_error: 0.1102 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1087 - mean_absolute_error: 0.1087 - val_loss: 0.1297 - val_mean_absolute_error: 0.1297\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1089 - mean_absolute_error: 0.1089 - val_loss: 0.1343 - val_mean_absolute_error: 0.1343\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1078 - mean_absolute_error: 0.1078 - val_loss: 0.1386 - val_mean_absolute_error: 0.1386\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1095 - mean_absolute_error: 0.1095 - val_loss: 0.1328 - val_mean_absolute_error: 0.1328\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1111 - mean_absolute_error: 0.1111 - val_loss: 0.1350 - val_mean_absolute_error: 0.1350\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1060 - mean_absolute_error: 0.1060 - val_loss: 0.1377 - val_mean_absolute_error: 0.1377\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1135 - mean_absolute_error: 0.1135 - val_loss: 0.1280 - val_mean_absolute_error: 0.1280\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1073 - mean_absolute_error: 0.1073 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1133 - mean_absolute_error: 0.1133 - val_loss: 0.1284 - val_mean_absolute_error: 0.1284\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1073 - mean_absolute_error: 0.1073 - val_loss: 0.1316 - val_mean_absolute_error: 0.1316\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1062 - mean_absolute_error: 0.1062 - val_loss: 0.1317 - val_mean_absolute_error: 0.1317\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1090 - mean_absolute_error: 0.1090 - val_loss: 0.1307 - val_mean_absolute_error: 0.1307\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1058 - mean_absolute_error: 0.1058 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1036 - mean_absolute_error: 0.1036 - val_loss: 0.1318 - val_mean_absolute_error: 0.1318\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1114 - mean_absolute_error: 0.1114 - val_loss: 0.1280 - val_mean_absolute_error: 0.1280\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1093 - mean_absolute_error: 0.1093 - val_loss: 0.1281 - val_mean_absolute_error: 0.1281\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1052 - mean_absolute_error: 0.1052 - val_loss: 0.1288 - val_mean_absolute_error: 0.1288\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1032 - mean_absolute_error: 0.1032 - val_loss: 0.1312 - val_mean_absolute_error: 0.1312\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1075 - mean_absolute_error: 0.1075 - val_loss: 0.1314 - val_mean_absolute_error: 0.1314\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1094 - mean_absolute_error: 0.1094 - val_loss: 0.1332 - val_mean_absolute_error: 0.1332\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1077 - mean_absolute_error: 0.1077 - val_loss: 0.1315 - val_mean_absolute_error: 0.1315\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1089 - mean_absolute_error: 0.1089 - val_loss: 0.1345 - val_mean_absolute_error: 0.1345\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1102 - mean_absolute_error: 0.1102 - val_loss: 0.1296 - val_mean_absolute_error: 0.1296\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1070 - mean_absolute_error: 0.1070 - val_loss: 0.1321 - val_mean_absolute_error: 0.1321\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1052 - mean_absolute_error: 0.1052 - val_loss: 0.1301 - val_mean_absolute_error: 0.1301\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1047 - mean_absolute_error: 0.1047 - val_loss: 0.1322 - val_mean_absolute_error: 0.1322\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1051 - mean_absolute_error: 0.1051 - val_loss: 0.1309 - val_mean_absolute_error: 0.1309\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1073 - mean_absolute_error: 0.1073 - val_loss: 0.1261 - val_mean_absolute_error: 0.1261\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1041 - mean_absolute_error: 0.1041 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1046 - mean_absolute_error: 0.1046 - val_loss: 0.1292 - val_mean_absolute_error: 0.1292\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1050 - mean_absolute_error: 0.1050 - val_loss: 0.1316 - val_mean_absolute_error: 0.1316\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1049 - mean_absolute_error: 0.1049 - val_loss: 0.1303 - val_mean_absolute_error: 0.1303\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1036 - mean_absolute_error: 0.1036 - val_loss: 0.1325 - val_mean_absolute_error: 0.1325\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1026 - mean_absolute_error: 0.1026 - val_loss: 0.1339 - val_mean_absolute_error: 0.1339\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1021 - mean_absolute_error: 0.1021 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1037 - mean_absolute_error: 0.1037 - val_loss: 0.1292 - val_mean_absolute_error: 0.1292\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1017 - mean_absolute_error: 0.1017 - val_loss: 0.1297 - val_mean_absolute_error: 0.1297\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1028 - mean_absolute_error: 0.1028 - val_loss: 0.1305 - val_mean_absolute_error: 0.1305\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1026 - mean_absolute_error: 0.1026 - val_loss: 0.1313 - val_mean_absolute_error: 0.1313\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1035 - mean_absolute_error: 0.1035 - val_loss: 0.1282 - val_mean_absolute_error: 0.1282\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1039 - mean_absolute_error: 0.1039 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1026 - mean_absolute_error: 0.1026 - val_loss: 0.1315 - val_mean_absolute_error: 0.1315\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1025 - mean_absolute_error: 0.1025 - val_loss: 0.1325 - val_mean_absolute_error: 0.1325\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1027 - mean_absolute_error: 0.1027 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1035 - mean_absolute_error: 0.1035 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1027 - mean_absolute_error: 0.1027 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1026 - mean_absolute_error: 0.1026 - val_loss: 0.1324 - val_mean_absolute_error: 0.1324\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1025 - mean_absolute_error: 0.1025 - val_loss: 0.1335 - val_mean_absolute_error: 0.1335\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1008 - mean_absolute_error: 0.1008 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1033 - mean_absolute_error: 0.1033 - val_loss: 0.1399 - val_mean_absolute_error: 0.1399\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1116 - mean_absolute_error: 0.1116 - val_loss: 0.1376 - val_mean_absolute_error: 0.1376\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1085 - mean_absolute_error: 0.1085 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1034 - mean_absolute_error: 0.1034 - val_loss: 0.1311 - val_mean_absolute_error: 0.1311\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1040 - mean_absolute_error: 0.1040 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1047 - mean_absolute_error: 0.1047 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Train-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.235487\n",
            "1         Spearmanr  0.227217\n",
            "2   Pearsonr >= 0.5 -0.039076\n",
            "3  Spearmanr >= 0.5 -0.041734\n",
            "Test-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.185711\n",
            "1         Spearmanr  0.096005\n",
            "2   Pearsonr >= 0.5  0.315529\n",
            "3  Spearmanr >= 0.5  0.261321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After pre-processing"
      ],
      "metadata": {
        "id": "0AkFWPb40kKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_NN(train, val, test, prePro=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyq15mRt0ZZR",
        "outputId": "073841e4-420e-4e48-9d97-861476ac5c31"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.2735 - mean_absolute_error: 0.2735 - val_loss: 0.1311 - val_mean_absolute_error: 0.1311\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1390 - mean_absolute_error: 0.1390 - val_loss: 0.1259 - val_mean_absolute_error: 0.1259\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1256 - mean_absolute_error: 0.1256 - val_loss: 0.1251 - val_mean_absolute_error: 0.1251\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1248 - mean_absolute_error: 0.1248 - val_loss: 0.1226 - val_mean_absolute_error: 0.1226\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1292 - mean_absolute_error: 0.1292 - val_loss: 0.1227 - val_mean_absolute_error: 0.1227\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.1297 - val_mean_absolute_error: 0.1297\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1396 - val_mean_absolute_error: 0.1396\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1213 - mean_absolute_error: 0.1213 - val_loss: 0.1313 - val_mean_absolute_error: 0.1313\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1209 - mean_absolute_error: 0.1209 - val_loss: 0.1273 - val_mean_absolute_error: 0.1273\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1338 - val_mean_absolute_error: 0.1338\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1230 - mean_absolute_error: 0.1230 - val_loss: 0.1360 - val_mean_absolute_error: 0.1360\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1295 - mean_absolute_error: 0.1295 - val_loss: 0.1404 - val_mean_absolute_error: 0.1404\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1330 - mean_absolute_error: 0.1330 - val_loss: 0.1358 - val_mean_absolute_error: 0.1358\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1254 - val_mean_absolute_error: 0.1254\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1219 - mean_absolute_error: 0.1219 - val_loss: 0.1365 - val_mean_absolute_error: 0.1365\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1200 - mean_absolute_error: 0.1200 - val_loss: 0.1296 - val_mean_absolute_error: 0.1296\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1197 - mean_absolute_error: 0.1197 - val_loss: 0.1262 - val_mean_absolute_error: 0.1262\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1250 - mean_absolute_error: 0.1250 - val_loss: 0.1478 - val_mean_absolute_error: 0.1478\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1208 - mean_absolute_error: 0.1208 - val_loss: 0.1270 - val_mean_absolute_error: 0.1270\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.1297 - val_mean_absolute_error: 0.1297\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1145 - mean_absolute_error: 0.1145 - val_loss: 0.1302 - val_mean_absolute_error: 0.1302\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1174 - mean_absolute_error: 0.1174 - val_loss: 0.1287 - val_mean_absolute_error: 0.1287\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1152 - mean_absolute_error: 0.1152 - val_loss: 0.1328 - val_mean_absolute_error: 0.1328\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1172 - mean_absolute_error: 0.1172 - val_loss: 0.1411 - val_mean_absolute_error: 0.1411\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1214 - mean_absolute_error: 0.1214 - val_loss: 0.1507 - val_mean_absolute_error: 0.1507\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1182 - mean_absolute_error: 0.1182 - val_loss: 0.1280 - val_mean_absolute_error: 0.1280\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1107 - mean_absolute_error: 0.1107 - val_loss: 0.1341 - val_mean_absolute_error: 0.1341\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1142 - mean_absolute_error: 0.1142 - val_loss: 0.1279 - val_mean_absolute_error: 0.1279\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1108 - mean_absolute_error: 0.1108 - val_loss: 0.1316 - val_mean_absolute_error: 0.1316\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1150 - mean_absolute_error: 0.1150 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1155 - mean_absolute_error: 0.1155 - val_loss: 0.1335 - val_mean_absolute_error: 0.1335\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1161 - mean_absolute_error: 0.1161 - val_loss: 0.1256 - val_mean_absolute_error: 0.1256\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1111 - mean_absolute_error: 0.1111 - val_loss: 0.1359 - val_mean_absolute_error: 0.1359\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1337 - mean_absolute_error: 0.1337 - val_loss: 0.1390 - val_mean_absolute_error: 0.1390\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1211 - mean_absolute_error: 0.1211 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1115 - mean_absolute_error: 0.1115 - val_loss: 0.1300 - val_mean_absolute_error: 0.1300\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1153 - mean_absolute_error: 0.1153 - val_loss: 0.1283 - val_mean_absolute_error: 0.1283\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1119 - mean_absolute_error: 0.1119 - val_loss: 0.1270 - val_mean_absolute_error: 0.1270\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1093 - mean_absolute_error: 0.1093 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1116 - mean_absolute_error: 0.1116 - val_loss: 0.1276 - val_mean_absolute_error: 0.1276\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1113 - mean_absolute_error: 0.1113 - val_loss: 0.1334 - val_mean_absolute_error: 0.1334\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1108 - mean_absolute_error: 0.1108 - val_loss: 0.1286 - val_mean_absolute_error: 0.1286\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1079 - mean_absolute_error: 0.1079 - val_loss: 0.1300 - val_mean_absolute_error: 0.1300\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1074 - mean_absolute_error: 0.1074 - val_loss: 0.1321 - val_mean_absolute_error: 0.1321\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1081 - mean_absolute_error: 0.1081 - val_loss: 0.1280 - val_mean_absolute_error: 0.1280\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1070 - mean_absolute_error: 0.1070 - val_loss: 0.1320 - val_mean_absolute_error: 0.1320\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1067 - mean_absolute_error: 0.1067 - val_loss: 0.1305 - val_mean_absolute_error: 0.1305\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1093 - mean_absolute_error: 0.1093 - val_loss: 0.1310 - val_mean_absolute_error: 0.1310\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1064 - mean_absolute_error: 0.1064 - val_loss: 0.1388 - val_mean_absolute_error: 0.1388\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1130 - mean_absolute_error: 0.1130 - val_loss: 0.1319 - val_mean_absolute_error: 0.1319\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1157 - mean_absolute_error: 0.1157 - val_loss: 0.1277 - val_mean_absolute_error: 0.1277\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1075 - mean_absolute_error: 0.1075 - val_loss: 0.1268 - val_mean_absolute_error: 0.1268\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1066 - mean_absolute_error: 0.1066 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1051 - mean_absolute_error: 0.1051 - val_loss: 0.1253 - val_mean_absolute_error: 0.1253\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1105 - mean_absolute_error: 0.1105 - val_loss: 0.1281 - val_mean_absolute_error: 0.1281\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1075 - mean_absolute_error: 0.1075 - val_loss: 0.1293 - val_mean_absolute_error: 0.1293\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1075 - mean_absolute_error: 0.1075 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1055 - mean_absolute_error: 0.1055 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1056 - mean_absolute_error: 0.1056 - val_loss: 0.1293 - val_mean_absolute_error: 0.1293\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1049 - mean_absolute_error: 0.1049 - val_loss: 0.1289 - val_mean_absolute_error: 0.1289\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1046 - mean_absolute_error: 0.1046 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1026 - mean_absolute_error: 0.1026 - val_loss: 0.1296 - val_mean_absolute_error: 0.1296\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1050 - mean_absolute_error: 0.1050 - val_loss: 0.1315 - val_mean_absolute_error: 0.1315\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1034 - mean_absolute_error: 0.1034 - val_loss: 0.1325 - val_mean_absolute_error: 0.1325\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1104 - mean_absolute_error: 0.1104 - val_loss: 0.1251 - val_mean_absolute_error: 0.1251\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1078 - mean_absolute_error: 0.1078 - val_loss: 0.1272 - val_mean_absolute_error: 0.1272\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1040 - mean_absolute_error: 0.1040 - val_loss: 0.1304 - val_mean_absolute_error: 0.1304\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1067 - mean_absolute_error: 0.1067 - val_loss: 0.1314 - val_mean_absolute_error: 0.1314\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1059 - mean_absolute_error: 0.1059 - val_loss: 0.1390 - val_mean_absolute_error: 0.1390\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1052 - mean_absolute_error: 0.1052 - val_loss: 0.1289 - val_mean_absolute_error: 0.1289\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1047 - mean_absolute_error: 0.1047 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1051 - mean_absolute_error: 0.1051 - val_loss: 0.1328 - val_mean_absolute_error: 0.1328\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1051 - mean_absolute_error: 0.1051 - val_loss: 0.1329 - val_mean_absolute_error: 0.1329\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1070 - mean_absolute_error: 0.1070 - val_loss: 0.1298 - val_mean_absolute_error: 0.1298\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1088 - mean_absolute_error: 0.1088 - val_loss: 0.1288 - val_mean_absolute_error: 0.1288\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1020 - mean_absolute_error: 0.1020 - val_loss: 0.1291 - val_mean_absolute_error: 0.1291\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1040 - mean_absolute_error: 0.1040 - val_loss: 0.1283 - val_mean_absolute_error: 0.1283\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1017 - mean_absolute_error: 0.1017 - val_loss: 0.1363 - val_mean_absolute_error: 0.1363\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1113 - mean_absolute_error: 0.1113 - val_loss: 0.1345 - val_mean_absolute_error: 0.1345\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1048 - mean_absolute_error: 0.1048 - val_loss: 0.1356 - val_mean_absolute_error: 0.1356\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1045 - mean_absolute_error: 0.1045 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1039 - mean_absolute_error: 0.1039 - val_loss: 0.1303 - val_mean_absolute_error: 0.1303\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1037 - mean_absolute_error: 0.1037 - val_loss: 0.1318 - val_mean_absolute_error: 0.1318\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1039 - mean_absolute_error: 0.1039 - val_loss: 0.1322 - val_mean_absolute_error: 0.1322\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1065 - mean_absolute_error: 0.1065 - val_loss: 0.1296 - val_mean_absolute_error: 0.1296\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1040 - mean_absolute_error: 0.1040 - val_loss: 0.1282 - val_mean_absolute_error: 0.1282\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1022 - mean_absolute_error: 0.1022 - val_loss: 0.1279 - val_mean_absolute_error: 0.1279\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1024 - mean_absolute_error: 0.1024 - val_loss: 0.1307 - val_mean_absolute_error: 0.1307\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1015 - mean_absolute_error: 0.1015 - val_loss: 0.1297 - val_mean_absolute_error: 0.1297\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1062 - mean_absolute_error: 0.1062 - val_loss: 0.1323 - val_mean_absolute_error: 0.1323\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1028 - mean_absolute_error: 0.1028 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1011 - mean_absolute_error: 0.1011 - val_loss: 0.1294 - val_mean_absolute_error: 0.1294\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1018 - mean_absolute_error: 0.1018 - val_loss: 0.1319 - val_mean_absolute_error: 0.1319\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1027 - mean_absolute_error: 0.1027 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0997 - mean_absolute_error: 0.0997 - val_loss: 0.1292 - val_mean_absolute_error: 0.1292\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1024 - mean_absolute_error: 0.1024 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1007 - mean_absolute_error: 0.1007 - val_loss: 0.1299 - val_mean_absolute_error: 0.1299\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0997 - mean_absolute_error: 0.0997 - val_loss: 0.1333 - val_mean_absolute_error: 0.1333\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1004 - mean_absolute_error: 0.1004 - val_loss: 0.1301 - val_mean_absolute_error: 0.1301\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1005 - mean_absolute_error: 0.1005 - val_loss: 0.1331 - val_mean_absolute_error: 0.1331\n",
            "Train-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.219795\n",
            "1         Spearmanr  0.208182\n",
            "2   Pearsonr >= 0.5 -0.025191\n",
            "3  Spearmanr >= 0.5 -0.034505\n",
            "Test-set \n",
            "            metrics     Value\n",
            "0          Pearsonr  0.206845\n",
            "1         Spearmanr  0.097236\n",
            "2   Pearsonr >= 0.5  0.305772\n",
            "3  Spearmanr >= 0.5  0.239704\n"
          ]
        }
      ]
    }
  ]
}